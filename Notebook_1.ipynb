{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICCIÓN DE LA PRODUCCIÓN DE ENERGÍA EÓLICA CON SCIKIT-LEARN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuración previa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "packages = ['pandas', 'numpy', 'matplotlib', 'seaborn', 'scikit-learn']\n",
    "\n",
    "for package in packages:\n",
    "    try:\n",
    "        __import__(package)\n",
    "    except ImportError:\n",
    "        install(package)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definicion de constantes usadas a lo largo del proyecto\n",
    "SEED = 100472050 # la semilla debe ser el NIA de uno de los integrantes\n",
    "wind_ava = pd.read_csv(\"data/wind_ava.csv\", index_col=0)\n",
    "wind_comp = pd.read_csv(\"data/wind_comp.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleccion de el molino 13 (sotavento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# la variable objetivo es la columna energy y solo queremos los datos que\n",
    "# terminan en 13, agregar la columna energy a wind_ava\n",
    "aux = wind_ava[wind_ava.columns[wind_ava.columns.str.endswith('13')]]\n",
    "# añadir la columna energy a wind_ava\n",
    "aux.insert(0, \"energy\", wind_ava[\"energy\"])     \n",
    "wind_ava = aux\n",
    "del aux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploración inicial\n",
    " - Estructura.\n",
    " - Tipos.\n",
    " - Identificación de valores faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(wind_ava.head())\n",
    "print(\"TYPES:\\n\",wind_ava.dtypes)\n",
    "display(\"NULLS:\", wind_ava.isnull().sum())\n",
    "# comprobar si hay columnas constantes\n",
    "print(wind_ava.columns[wind_ava.nunique() == 1].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que todos los datos son continuos, no hay NANs ni NULLS y no hay columnas constantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estadísticas descriptivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(wind_ava.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Busqueda de valores atipicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_plots = len(wind_ava.columns)\n",
    "num_rows = -(-num_plots // 5)  \n",
    "\n",
    "fig, axs = plt.subplots(num_rows, 5, figsize=(15, 3*num_rows))\n",
    "\n",
    "axs = axs.flatten() # Aplanar el array de ejes para facilitar el acceso\n",
    "\n",
    "for i, column in enumerate(wind_ava.columns):\n",
    "    sns.boxplot(x=wind_ava[column], ax=axs[i])\n",
    "    axs[i].set_title(f\"Boxplot de la variable {column} en wind_ava\")\n",
    "\n",
    "# Ocultar ejes sobrantes\n",
    "for j in range(i+1, len(axs)):\n",
    "    axs[j].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creacion de un dataset SIN valores atipicos (vamos a no sobreescribir el otro para poder comparar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = wind_ava.quantile(0.25)\n",
    "Q3 = wind_ava.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Límites para identificar valores atípicos\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Identificar valores atípicos\n",
    "outliers = (wind_ava < lower_bound) | (wind_ava > upper_bound)\n",
    "\n",
    "# Tratar los valores atípicos eliminándolos del conjunto de datos\n",
    "wind_ava_no_outliers = wind_ava[~outliers.any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis univariado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramas para cada variable\n",
    "''' # Descomentar para ver los histogramas de las variables con outliers, son muy similares a los de las variables sin outliers.\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, column in enumerate(wind_ava.columns):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    sns.histplot(wind_ava[column], kde=True)\n",
    "    plt.title(column)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "'''\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, column in enumerate(wind_ava_no_outliers.columns):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    sns.histplot(wind_ava_no_outliers[column], kde=True)\n",
    "    plt.title(column)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo mas relevante de estas graficas son, tanto los picos en 0 en cape y en fsr, que como tambien veremos mas adelante estan muy relacionados.\n",
    "El hecho de que la distribucion de los valores de cape sea asi tambien hace pensar que podemos tener problemas en el futuro, ya que el modelo puede  predecir siempre cape=0 con una precision bastante alta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis multivariado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrices de correalcion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlacion general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlacion entre las variables \n",
    "correlation = wind_ava_no_outliers.corr()\n",
    "# poner correlaciones en valor absoluto\n",
    "correlation = correlation.abs()\n",
    "# mostrar la matriz de correlacion\n",
    "plt.figure(figsize=(15, 15))\n",
    "sns.heatmap(correlation, annot=True, cmap=\"GnBu\", fmt=\".2f\")\n",
    "plt.title(\"Matriz de correlación de wind_ava\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlacion con la variable cape.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_cape13 = abs(correlation['energy']).sort_values(ascending=False)[1:]\n",
    "# plot de las correlaciones\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=correlation_cape13.index, y=correlation_cape13)\n",
    "plt.title(\"Correlación de las variables con energy\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlacion de cada variable con las demas (util para saber que variables pueden ser combinadas o eliminadas ya que aportan la misma información)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint as pp\n",
    "\n",
    "# Para cada columna, encuentra las variables más correlacionadas\n",
    "correlation_dict = {}\n",
    "n = 2 # encontrar las n variables más correlacionadas, establecer n>23 para ver todas las variables\n",
    "for col in correlation.columns:\n",
    "    correlation_dict[col] = correlation[col].sort_values(ascending=False)[1:n+1].to_dict()\n",
    "\n",
    "pp.pprint(correlation_dict, compact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que hay variables que estan muy altamente correlacionadas entre si, con correlaciones cercanas a 1, habra que decidir que hacer con estas variables ya que a priori no parecen muy utiles al aportar la misma información"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sistemas de evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación Outer e Inner, seleccion de las medidas del Error\n",
    "\n",
    "Como hemos podido observar en el EDA, los datos contienen una gran cantidad de datos atipicos, que podemos suponer que hay ruido en los datos, es por ello que vamos a descartar MSE como medida pues es muy probable que sobreestime el error.\n",
    "Ademas los valores de cape.13 van desde 0 en la mayoria de casos a varios miles en otros, lo cual tambien es un problema con el MSE, por lo que podriamos plantearnos emplear MPSE, aun asi debido a los valores atipicos esta medida tampoco nos parece la ideal. \n",
    "Lo mismo ocurre aun que en menor medida con RMSE Y RMSPE.\n",
    "Una medida que poriamos plantearnos usar es MAPE o MAE para solucionar este problema con los valores atipicos, pero nos introduce de nuevo conflicto con el gran rango de valores que toma cape.13.\n",
    "\n",
    "Teniendo esto en cuenta consideramos que las mejores medidas del error para este caso son:\n",
    "- R2\n",
    "- **RMSE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creación de un modelo dummy\n",
    "\n",
    "Basandonos en las medidas seleccionadas anteriormente vamos a crear un regresor dummy y evaluarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "# Primero, dividiremos los datos en entrenamiento y test\n",
    "X = wind_ava.drop(columns='energy')\n",
    "y = wind_ava['energy']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "\n",
    "# Entrenar un modelo de regresión \"dummy\" que prediga la media\n",
    "# Este modelo es útil como referencia para comparar con otros modelos en el futuro\n",
    "dummy = DummyRegressor(strategy=\"mean\")\n",
    "dummy.fit(X_train, y_train)\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(metrics.mean_squared_error(y_true, y_pred))\n",
    "\n",
    "dummy_rmse = rmse(y_test, dummy.predict(X_test))\n",
    "dummy_r2 = metrics.r2_score(y_test, dummy.predict(X_test))\n",
    "dummy_mae = metrics.mean_absolute_error(y_test, dummy.predict(X_test))\n",
    "\n",
    "print(f\"RMSE del modelo dummy: {dummy_rmse:.2f}\")\n",
    "print(f\"R^2 del modelo dummy: {dummy_r2:.2f}\")\n",
    "print(f\"MAE del modelo dummy: {dummy_mae:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar, haciendo uso de dos modelos de regresión \"dummy\" se tiene a un error cuadrático medio elevado.\n",
    "Este modelo lo usaremos para comparar con nuestro modelo real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metodo de Escalado con KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "#normalizacion por escala min-max\n",
    "min_max = make_column_transformer(\n",
    "    (MinMaxScaler(), X_train.columns)\n",
    ")\n",
    "\n",
    "#normalizacion por escala estandar\n",
    "standard = make_column_transformer(\n",
    "    (StandardScaler(), X_train.columns)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escalado min-max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import time\n",
    "\n",
    "pipe_knn = Pipeline([\n",
    "        ('preproceso', min_max), #entrada del pipeline\n",
    "        ('regresor', KNeighborsRegressor()) #salida del pipeline\n",
    "])\n",
    "\n",
    "np.random.seed(SEED)\n",
    "\n",
    "t1 = time.time()\n",
    "pipe_knn.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "\n",
    "y_test_pred = pipe_knn.predict(X_test)\n",
    "\n",
    "rmse_knn = np.sqrt(metrics.mean_squared_error(y_test, y_test_pred))\n",
    "r2_knn = metrics.r2_score(y_test, y_test_pred)\n",
    "print(f\"RMSE: {rmse_knn}\")\n",
    "print(f\"R2: {r2_knn}\")\n",
    "print(\"Tiempo de entrenamiento: \", t2 - t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escalado estandar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import time\n",
    "\n",
    "pipe_knn = Pipeline([\n",
    "        ('preproceso', standard), #entrada del pipeline\n",
    "        ('regresor', KNeighborsRegressor()) #salida del pipeline\n",
    "])\n",
    "\n",
    "np.random.seed(SEED)\n",
    "\n",
    "t1 = time.time()\n",
    "pipe_knn.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "\n",
    "y_test_pred = pipe_knn.predict(X_test)\n",
    "\n",
    "rmse_knn = np.sqrt(metrics.mean_squared_error(y_test, y_test_pred))\n",
    "r2_knn = metrics.r2_score(y_test, y_test_pred)\n",
    "print(f\"RMSE: {rmse_knn}\")\n",
    "print(f\"R2: {r2_knn}\")\n",
    "print(\"Tiempo de entrenamiento: \", t2 - t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El escalado min-max es el que mejor se ajusta a los datos, por lo que lo usaremos en el resto del notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 puntos A continuación, se considerarán estos métodos: KNN, árboles de regresión, regresión lineal (la normal y al menos, la variante Lasso) y SVM:\n",
    "a.\tSe evaluarán dichos modelos con sus hiperparámetros por omisión. También se medirán los tiempos que tarda el entrenamiento.\n",
    "\n",
    "b.\tDespués, se ajustarán los hiperparámetros más importantes de cada método y se obtendrá su evaluación. Medir tiempos del entrenamiento, ahora con HPO.\n",
    "\n",
    "c.\tObtener algunas conclusiones, tales como: ¿cuál es el mejor método? ¿Cuál de los métodos básicos de aprendizaje automático es más rápido? ¿Los resultados son mejores que los regresores triviales/naive/dummy? ¿El ajuste de hiperparámetros mejora con respecto a los valores por omisión? ¿Hay algún equilibrio entre tiempo de ejecución y mejora de resultados? ¿Es posible extraer de alguna técnica qué atributos son más relevantes? etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluacion de los modelos con los parametros por defecto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regresor knn con parametros por defecto \n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "pipe_knn = Pipeline([\n",
    "        ('preproceso', standard),\n",
    "        ('regresor', KNeighborsRegressor())\n",
    "])\n",
    "\n",
    "# Entrenar el modelo\n",
    "t1 = time.time()\n",
    "pipe_knn.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "\n",
    "dt_knn = t2 - t1 \n",
    "\n",
    "# Predecir los valores de test\n",
    "y_test_pred = pipe_knn.predict(X_test)\n",
    "\n",
    "# Calcular métricas\n",
    "rmse_knn = np.sqrt(metrics.mean_squared_error(y_test, y_test_pred))\n",
    "r2_knn = metrics.r2_score(y_test, y_test_pred)\n",
    "print(f\"RMSE: {rmse_knn}\")\n",
    "print(f\"R2: {r2_knn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arboles de regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arbol de regresion con parametros por defecto\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "pipe_tree = Pipeline([\n",
    "        ('preproceso', standard),\n",
    "        ('regresor', DecisionTreeRegressor())\n",
    "])\n",
    "\n",
    "# Entrenar el modelo\n",
    "t1 = time.time()\n",
    "pipe_tree.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "\n",
    "dt_tree = t2 - t1\n",
    "\n",
    "# Predecir los valores de test\n",
    "y_test_pred = pipe_tree.predict(X_test)\n",
    "\n",
    "# Calcular métricas\n",
    "rmse_tree = np.sqrt(metrics.mean_squared_error(y_test, y_test_pred))\n",
    "r2_tree = metrics.r2_score(y_test, y_test_pred)\n",
    "print(f\"RMSE: {rmse_tree}\")\n",
    "print(f\"R2: {r2_tree}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regresion lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regresion lineal con parametros por defecto\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "pipe_lr = Pipeline([\n",
    "        ('preproceso', standard),\n",
    "        ('regresor', LinearRegression())\n",
    "])\n",
    "\n",
    "# Entrenar el modelo\n",
    "t1 = time.time()\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "\n",
    "dt_lr = t2 - t1\n",
    "# Predecir los valores de test\n",
    "y_test_pred = pipe_lr.predict(X_test)\n",
    "\n",
    "# Calcular métricas\n",
    "rmse_lr = np.sqrt(metrics.mean_squared_error(y_test, y_test_pred))\n",
    "r2_lr = metrics.r2_score(y_test, y_test_pred)\n",
    "print(f\"RMSE: {rmse_lr}\")\n",
    "print(f\"R2: {r2_lr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regresion Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regresor lasso con parametros por defecto\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "pipe_lasso = Pipeline([\n",
    "        ('preproceso', standard),\n",
    "        ('regresor', Lasso(max_iter=10000))\n",
    "])\n",
    "\n",
    "# Entrenar el modelo\n",
    "t1 = time.time()\n",
    "pipe_lasso.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "\n",
    "dt_lasso = t2 - t1\n",
    "# Predecir los valores de test\n",
    "y_test_pred = pipe_lasso.predict(X_test)\n",
    "\n",
    "# Calcular métricas\n",
    "rmse_lasso = np.sqrt(metrics.mean_squared_error(y_test, y_test_pred))\n",
    "r2_lasso = metrics.r2_score(y_test, y_test_pred)\n",
    "print(f\"RMSE: {rmse_lasso}\")\n",
    "print(f\"R2: {r2_lasso}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM con parametros por defecto\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "pipe_svm = Pipeline([\n",
    "        ('preproceso', standard),\n",
    "        ('regresor', SVR())\n",
    "])\n",
    "\n",
    "# Entrenar el modelo\n",
    "t1 = time.time()\n",
    "pipe_svm.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "\n",
    "dt_svm = t2 - t1\n",
    "\n",
    "# Predecir los valores de test\n",
    "y_test_pred = pipe_svm.predict(X_test)\n",
    "\n",
    "# Calcular métricas\n",
    "rmse_svm = np.sqrt(metrics.mean_squared_error(y_test, y_test_pred))\n",
    "r2_svm = metrics.r2_score(y_test, y_test_pred)\n",
    "print(f\"RMSE: {rmse_svm}\")\n",
    "print(f\"R2: {r2_svm}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest con parametros por defecto\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "pipe_rf = Pipeline([\n",
    "        ('preproceso', standard),\n",
    "        ('regresor', RandomForestRegressor())\n",
    "])\n",
    "\n",
    "# Entrenar el modelo\n",
    "t1 = time.time()\n",
    "pipe_rf.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "\n",
    "dt_rf = t2 - t1\n",
    "\n",
    "# Predecir los valores de test\n",
    "y_test_pred = pipe_rf.predict(X_test)\n",
    "\n",
    "# Calcular métricas\n",
    "rmse_rf = np.sqrt(metrics.mean_squared_error(y_test, y_test_pred))\n",
    "r2_rf = metrics.r2_score(y_test, y_test_pred)\n",
    "print(f\"RMSE: {rmse_rf}\")\n",
    "print(f\"R2: {r2_rf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluacion de los modelos con los hiperparametros ajustados\n",
    "Usando RMSE para la evaluacion interna y RMSE y R2 para la externa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajuste de hiperparametros para knn basandonos en rmse\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'regresor__n_neighbors': range(1, 21),\n",
    "    'regresor__weights': ['uniform', 'distance'],\n",
    "    'regresor__p': [1, 2]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe_knn, param_grid, cv=5, scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "t1 = time.time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "dt_knn_hpo = t2 - t1\n",
    "\n",
    "print(\"Mejores hiperparámetros encontrados:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Calcular métricas\n",
    "best_model = grid_search.best_estimator_\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "print(\"Evaluacion externa:\")\n",
    "rmse_knn_hpo = np.sqrt(metrics.mean_squared_error(y_test, y_test_pred))\n",
    "r2_knn_hpo = best_model.score(X_test, y_test)\n",
    "print(f\"RMSE: {rmse_knn_hpo}\")\n",
    "print(f\"R2: {r2_knn_hpo}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arboles de regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajuste de hiperparametros para arbol de regresion basandonos en rmse\n",
    "\n",
    "param_grid = {\n",
    "    'regresor__max_depth': range(1, 11),\n",
    "    'regresor__min_samples_split': range(2, 11),\n",
    "    'regresor__min_samples_leaf': range(1, 11)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe_tree, param_grid, cv=5, scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "t1 = time.time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "\n",
    "dt_tree_hpo = t2 - t1\n",
    "\n",
    "print(\"Mejores hiperparámetros encontrados:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Calcular métricas\n",
    "best_model = grid_search.best_estimator_\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "print(\"Evaluacion externa:\")\n",
    "rmse_tree_hpo = np.sqrt(metrics.mean_squared_error(y_test, y_test_pred))\n",
    "r2_tree_hpo = best_model.score(X_test, y_test)\n",
    "print(f\"RMSE: {rmse_tree_hpo}\")\n",
    "print(f\"R2: {r2_tree_hpo}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regresion lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajuste de hiperparametros para regresion lineal basandonos en rmse\n",
    "\n",
    "param_grid = {\n",
    "    'regresor__fit_intercept': [True, False]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe_lr, param_grid, cv=5, scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "t1 = time.time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "dt_regresion_lineal_hpo = t2 - t1\n",
    "\n",
    "print(\"Mejores hiperparámetros encontrados:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Calcular métricas\n",
    "best_model = grid_search.best_estimator_\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "print(\"Evaluacion externa:\")\n",
    "rmse_lr_hpo = np.sqrt(metrics.mean_squared_error(y_test, y_test_pred))\n",
    "r2_lr_hpo = best_model.score(X_test, y_test)\n",
    "print(f\"RMSE: {rmse_lr_hpo}\")\n",
    "print(f\"R2: {r2_lr_hpo}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regresion Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajuste de hiperparametros para lasso basandonos en rmse\n",
    " \n",
    "param_grid = {\n",
    "    'regresor__alpha': np.logspace(-4, 4, 9)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe_lasso, param_grid, cv=5, scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "t1 = time.time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "\n",
    "dt_laso_hpo = t2 - t1\n",
    "\n",
    "print(\"Mejores hiperparámetros encontrados:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Calcular métricas\n",
    "best_model = grid_search.best_estimator_\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "print(\"Evaluacion externa:\")\n",
    "rmse_lasso_hpo = np.sqrt(metrics.mean_squared_error(y_test, y_test_pred))\n",
    "r2_lasso_hpo = best_model.score(X_test, y_test)\n",
    "print(f\"RMSE: {rmse_lasso_hpo}\")\n",
    "print(f\"R2: {r2_lasso_hpo}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ajuste de hiperparametros para svm basandonos en rmse\n",
    "\n",
    "param_grid = {\n",
    "    'regresor__C': np.logspace(-4, 4, 9),\n",
    "    'regresor__gamma': np.logspace(-4, 4, 9)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe_svm, param_grid, cv=5, scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "t1 = time.time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "\n",
    "dt_svm_hpo = t2 - t1\n",
    "\n",
    "print(\"Mejores hiperparámetros encontrados:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Calular métricas\n",
    "best_model = grid_search.best_estimator_\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "print(\"Evaluacion externa:\")\n",
    "rmse_svm_hpo = np.sqrt(metrics.mean_squared_error(y_test, y_test_pred))\n",
    "r2_svm_hpo = best_model.score(X_test, y_test)\n",
    "print(f\"RMSE: {rmse_svm_hpo}\")\n",
    "print(f\"R2: {r2_svm_hpo}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ajuste de hiperparametros para random forest basandonos en rmse\n",
    "\n",
    "param_grid = {\n",
    "    'regresor__n_estimators': [150, 200],\n",
    "    'regresor__max_depth': [20, None],\n",
    "    'regresor__min_samples_split': [5, 10],\n",
    "    'regresor__min_samples_leaf': [2, 4],\n",
    "    'regresor__bootstrap': [True]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe_rf, param_grid, cv=5, scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "# medir tiempo de entrenamiento\n",
    "t1 = time.time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "dt_random_forest_hpo = t2 - t1\n",
    "print(\"Mejores hiperparámetros encontrados:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Calcular métricas\n",
    "best_model = grid_search.best_estimator_\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "print(\"Evaluacion externa:\")\n",
    "rmse_rf_hpo = np.sqrt(metrics.mean_squared_error(y_test, y_test_pred))\n",
    "r2_rf_hpo = best_model.score(X_test, y_test)\n",
    "print(f\"RMSE: {rmse_rf_hpo}\")\n",
    "print(f\"R2: {r2_rf_hpo}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Habiendo obtenido los resultados de los modelos con los hiperparametros ajustados, vamos a compararlos con los resultados obtenidos con los hiperparametros por defecto para distinguir qué modelo será empleado en la predicción de la producción de energía."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Graficaremos los resultados de los modelos con los hiperparametros ajustados y los hiperparametros por defecto\n",
    "\n",
    "# RMSE\n",
    "rmse = [rmse_knn, rmse_tree, rmse_lr, rmse_lasso, rmse_svm, rmse_rf]\n",
    "rmse_hpo = [rmse_knn_hpo, rmse_tree, rmse_lr_hpo, rmse_lasso_hpo, rmse_svm_hpo, rmse_rf_hpo]\n",
    "\n",
    "# R2\n",
    "r2 = [r2_knn, r2_tree, r2_lr, r2_lasso, r2_svm, r2_rf]\n",
    "r2_hpo = [r2_knn_hpo, r2_tree, r2_lr_hpo, r2_lasso_hpo, r2_svm_hpo, r2_rf_hpo]\n",
    "\n",
    "# tiempos\n",
    "tiempos = [dt_knn, dt_tree, dt_lr, dt_lasso, dt_svm, dt_rf]\n",
    "tiempos_hpo = [dt_knn_hpo, dt_tree_hpo, dt_regresion_lineal_hpo, dt_laso_hpo, dt_svm_hpo, dt_random_forest_hpo]\n",
    "\n",
    "\n",
    "# Crear un DataFrame con los resultados\n",
    "results = pd.DataFrame({\n",
    "    'RMSE': rmse,\n",
    "    'RMSE HPO': rmse_hpo,\n",
    "    'R2': r2,\n",
    "    'R2 HPO': r2_hpo,\n",
    "}, index=['KNN', 'Tree', 'LR', 'Lasso', 'SVM', 'RF'])\n",
    "\n",
    "# Graficar los resultados\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "results[['RMSE', 'RMSE HPO']].plot(kind='bar', ax=axs[0])\n",
    "axs[0].set_title('RMSE de los modelos')\n",
    "axs[0].set_ylabel('RMSE')\n",
    "axs[0].set_xlabel('Modelo')\n",
    "\n",
    "results[['R2', 'R2 HPO']].plot(kind='bar', ax=axs[1])\n",
    "axs[1].set_title('R2 de los modelos')\n",
    "axs[1].set_ylabel('R2')\n",
    "axs[1].set_xlabel('Modelo')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Graficar los tiempos de entrenamiento en horizontal, azul para los modelos con hiperparámetros por defecto y naranja para los modelos con hiperparámetros ajustados\n",
    "time_results = pd.DataFrame({\n",
    "    'Tiempo de entrenamiento': tiempos,\n",
    "    'Tiempo de entrenamiento HPO': tiempos_hpo,\n",
    "}, index=['KNN', 'Tree', 'LR', 'Lasso', 'SVM', 'RF'])\n",
    "\n",
    "ax = time_results.plot(kind='bar', figsize=(10, 5))\n",
    "plt.title('Tiempo de entrenamiento de los modelos')\n",
    "ax.set_yscale('log')\n",
    "plt.xlabel('Tiempo (s)')\n",
    "plt.ylabel('Modelo')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Como se puede observar, los modelos más prometedores son el Random Forest y el SVM, destacando éste último en el significativo cambio del error con el ajuste de hiperparámetros. No obstante, el mejor modelo es el Random Forest, ya que tiene un menor error y un mayor R2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección del mejor modelo\n",
    "Hemos seleccinado random forest por que a pesar de tardar mas en entrenarse es el mejor modelo en cuanto a error y R2.\n",
    "Para la optimización de los hiperparámetros ibamos a usar un gridsearch, pero debido a la cantidad de datos y a la cantidad de hiperparámetros que tiene el modelo era inviable (60-100 horas).\n",
    "Despues consideramos usar un randomsearch, pero los resultados obtenidos no eran satisfactorios.\n",
    "Es por ello que hemos decidido utilizar optuna, que es una libreria que nos permite optimizar los hiperparámetros de una forma mas eficiente mediante una busqueda bayesiana, sin embargo sigue siendo un proceso lento, aproximadamente 7h, por lo que lo hemos ejecutado y anotado los resultados para no necesitar recalcularlo. Si se quiere replicar el proceso hay que descomentar las lineas que se señalan en el codigo y ejecutarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import optuna\n",
    "except ImportError:\n",
    "    %pip install optuna\n",
    "    import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 200, 350),\n",
    "        'max_depth': trial.suggest_int('max_depth', 20, 40),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 7),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 5),\n",
    "        'bootstrap':  trial.suggest_categorical('bootstrap', [True])\n",
    "    }\n",
    "    # print(f\"Trial {trial.number} - Iniciando entrenamiento con hiperparámetros: {params}\")\n",
    "    \n",
    "    model = RandomForestRegressor(**params)\n",
    "    rmse_scores = []\n",
    "    for _ in range(10):  # 10-fold cross-validation\n",
    "        X_fold_train, X_fold_val, y_fold_train, y_fold_val = train_test_split(X_train, y_train, test_size=0.1, random_state=SEED)\n",
    "        model.fit(X_fold_train, y_fold_train)\n",
    "        y_pred = model.predict(X_fold_val)\n",
    "        rmse = metrics.root_mean_squared_error(y_fold_val, y_pred)\n",
    "        rmse_scores.append(rmse)\n",
    "    \n",
    "    # print(f\"Trial {trial.number} - RMSE: {np.mean(rmse_scores)}\")\n",
    "    return np.mean(rmse_scores)\n",
    "\n",
    "def progress_callback(study, trial):\n",
    "    print(f\"Trial {trial.number} finished with value: {trial.value} and parameters: {trial.params}\")\n",
    "    print(f\"Best trial so far: {study.best_trial.number}\")\n",
    "\n",
    "\n",
    "\n",
    "# WARINING: Este proceso puede tardar mucho tiempo en completarse (5-10 horas)\n",
    "\n",
    "# study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=SEED))\n",
    "\n",
    "# print(\"Iniciando búsqueda de hiperparámetros...\")\n",
    "# descomentar la siguiente linea para ejecutar la busqueda de hiperparametros \n",
    "# study.optimize(objective, n_trials=1000, n_jobs=-1, callbacks=[progress_callback], show_progress_bar=True)\n",
    "# best_params = study.best_params\n",
    "# comentar la siguiente linea para ejecutar la busqueda de hiperparametros\n",
    "best_params ={'n_estimators': 333, 'max_depth': 34, 'min_samples_split': 2, 'min_samples_leaf': 2, 'bootstrap': True}\n",
    "\n",
    "print(\"Mejores hiperparámetros encontrados:\")\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el mejor modelo con los mejores hiperparámetros\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "\n",
    "best_model = RandomForestRegressor(**best_params)\n",
    "t1 = time.time()\n",
    "best_model.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "dt = t2 - t1\n",
    "# Predecir los valores de test\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calcular métricas\n",
    "rmse_rf_cv = metrics.root_mean_squared_error(y_test, y_test_pred)\n",
    "r2_rf_cv = best_model.score(X_test, y_test)\n",
    "print(f\"RMSE: {rmse_rf_cv}\")\n",
    "print(f\"R2: {r2_rf_cv}\")\n",
    "print(\"Tiempo de entrenamiento: \", dt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrenar con los mejores hiperparametros encontrados y todos los datos\n",
    "best_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exportar el modelo en un archivo pickle\n",
    "import pickle\n",
    "\n",
    "with open('model.pkl', 'wb') as file:\n",
    "    pickle.dump(best_model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medir la precision del modelo en energy alto y energy bajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medir la precision del modelo en energy alto y energy bajo\n",
    "# dividir el conjunto de datos en dos, uno con energy alto y otro con energy bajo\n",
    "# cuando la energía sea menor que el tercer cuantil, se considerará clase “baja”, y \n",
    "# cuando sea mayor, clase  “alta”.\n",
    "low_energy = wind_ava[wind_ava['energy'] < wind_ava['energy'].quantile(1/3)]\n",
    "high_energy = wind_ava[wind_ava['energy'] > wind_ava['energy'].quantile(2/3)]\n",
    "\n",
    "X_low = low_energy.drop(columns='energy')\n",
    "y_low = low_energy['energy']\n",
    "\n",
    "X_high = high_energy.drop(columns='energy')\n",
    "y_high = high_energy['energy']\n",
    "\n",
    "# medir el rendimiento en el conjunto de datos con energía baja\n",
    "y_low_pred = best_model.predict(X_low)\n",
    "rmse_low = np.sqrt(metrics.mean_squared_error(y_low, y_low_pred))\n",
    "r2_low = best_model.score(X_low, y_low)\n",
    "\n",
    "# medir el rendimiento en el conjunto de datos con energía alta\n",
    "y_high_pred = best_model.predict(X_high)\n",
    "rmse_high = np.sqrt(metrics.mean_squared_error(y_high, y_high_pred))\n",
    "r2_high = best_model.score(X_high, y_high)\n",
    "\n",
    "print(f\"RMSE en energía baja: {rmse_low}\")\n",
    "print(f\"R2 en energía baja: {r2_low}\")\n",
    "\n",
    "print(f\"RMSE en energía alta: {rmse_high}\")\n",
    "print(f\"R2 en energía alta: {r2_high}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convertir el problema en uno de clasificacion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETIQUETAR LOS DATOS COMO LOW Y HIGH energy\n",
    "# añadir una columna al conjunto de datos original que indique si la energía es baja o alta\n",
    "wind_ava['energy_class'] = 'high'\n",
    "wind_ava.loc[wind_ava['energy'] < wind_ava['energy'].quantile(1/3), 'energy_class'] = 'low'\n",
    "# eliminar la columna energy\n",
    "wind_ava.drop(columns='energy', inplace=True)\n",
    "\n",
    "wind_ava.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
